{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from scipy import stats\n",
    "from sklearn.decomposition import PCA\n",
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "from evaluation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# goal: choose alpha ST RT-zOGF using ms_df is highest\n",
    "# load dfs\n",
    "cwd = os.getcwd()\n",
    "df = pd.read_csv(f\"{cwd}/7-29_acc_df.csv\")\n",
    "mu_sig_df = pd.read_csv(f\"{cwd}/mu_sig_df.csv\")\n",
    "baseline_df = df[df['algorithm'].isin(['pca', 'tsne', 'pacmap', 'umap'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mu, sigma\n",
    "metrics = ['rt', 'knn']\n",
    "mean_and_std = dict()\n",
    "# metric way\n",
    "for metric in metrics:\n",
    "    metric_df = baseline_df[metric] \n",
    "    mu = metric_df.median() # use median\n",
    "    sigma = metric_df.std()\n",
    "    print(metric, \"mu =\", mu, \"sigma =\", sigma)\n",
    "    print(\"median =\", metric_df.median())\n",
    "    mean_and_std[metric] = (mu, sigma)\n",
    "    \n",
    "    metric_zscores = (df[metric] - mu) / sigma # compute z-scores across all methods\n",
    "    zdf[metric] = metric_zscores\n",
    "\n",
    "zdf['ogf'] = 0.5*zdf['rt'] + 0.5*zdf['knn'] # compute RT-zOGF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mu, sigma for rt plus knn\n",
    "rt_knn_df = baseline_df['knn'] + baseline_df['rt']\n",
    "mu = rt_knn_df.median()\n",
    "sigma = rt_knn_df.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each dataset:\n",
    "# load PCA, UMAP embeddings of each dataset\n",
    "# concatenate accordingly\n",
    "# find RT, kNN of each embedding\n",
    "# store RT, kNN, RT-kNN, and OGF in dataframe\n",
    "# print out table showing alpha star versus other methods\n",
    "\n",
    "\n",
    "# once have all the datasets:\n",
    "# print out table showing ideal alpha for each dataset\n",
    "# print out new table\n",
    "\n",
    "# need dataframe storing: \n",
    "# algorithm (alpha size), dataset, RT, kNN, RT-kNN, OGF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### just to check, mini Muraro example ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_list = [str(np.round(item,1)) for item in np.linspace(0,1,11)] # this rounding is for step size 0.1 -- for step size 0.05, change it to 2!!!\n",
    "#datasets = ['CAFs', 'CellMix', 'Duo4eq', 'Duo8eq','FMNIST','Kang','MNIST','Muraro','TMLung','TMPanc']\n",
    "datasets = ['Muraro']\n",
    "results = []\n",
    "\n",
    "for dataset in datasets:\n",
    "    # load PCA, UMAP embeddings\n",
    "    pcaM = umapM = np.load(f'{cwd}/embeddings/'+ dataset + '/'+ dataset + '_pca.npy')\n",
    "    umapM = np.load(f'{cwd}/embeddings/'+ dataset + '/'+ dataset + '_umap.npy')\n",
    "\n",
    "    # load Xtrain, ytrain\n",
    "    if dataset == 'CAFs':\n",
    "        expr = pd.read_csv(f'{cwd}/data/CAFs.txt', sep='\\t')\n",
    "        X_train = expr.values[:,0:(expr.shape[1]-1)]\n",
    "        X_train = np.log(X_train + 1)\n",
    "        y_train = expr.values[:,expr.shape[1]-1]\n",
    "    \n",
    "    elif dataset =='CellMix':\n",
    "        df = pd.read_csv(f'{cwd}/data/pcadata_CellMix.csv')\n",
    "        X_train = df.values[:,0:(df.shape[1]-1)]\n",
    "        y_train = df.values[:,df.shape[1]-1]\n",
    "\n",
    "    elif dataset =='CellMixLA':\n",
    "        df = pd.read_csv(f'{cwd}/data/pcadata_CellMix_WithLocAvg.csv')\n",
    "        X_train = df.values[:,0:(df.shape[1]-1)]\n",
    "        y_train = df.values[:,df.shape[1]-1]\n",
    "    \n",
    "    elif dataset =='Duo4eq':\n",
    "        X_train = np.load(f\"{cwd}/data/4eq_log_pca.npy\")\n",
    "        y_train = np.load(f\"{cwd}/data/4eq_labels.npy\")\n",
    "\n",
    "    elif dataset =='Duo8eq':\n",
    "        X_train = np.load(f\"{cwd}/data/8eq_log_pca.npy\")\n",
    "        y_train = np.load(f\"{cwd}/data/8eq_labels.npy\")\n",
    "\n",
    "    elif dataset == 'FMNIST':\n",
    "        source_df = pd.read_csv(f\"{cwd}/data/fashion-mnist.csv\")\n",
    "        X_train = source_df.iloc[:,:].values.astype(np.float32)\n",
    "        y_train = source_df[\"class\"].values \n",
    "\n",
    "    elif dataset =='Kang':\n",
    "        X_train = np.load(f\"{cwd}/data/kang_log_pca.npy\")\n",
    "        y_train = np.load(f\"{cwd}/data/kang_labels.npy\")\n",
    "\n",
    "    elif dataset =='MNIST':\n",
    "        mnist = ds.fetch_openml('mnist_784', version=1, as_frame=False)\n",
    "        X_train = mnist.data\n",
    "        y_train = mnist.target.astype(int)\n",
    "    \n",
    "    elif dataset == 'Muraro':\n",
    "        X_train = np.load(f\"{cwd}/data/muraro_log_pca.npy\")\n",
    "        y_train = np.load(f\"{cwd}/data/muraro_labels.npy\")\n",
    "\n",
    "    elif dataset =='TMLung':\n",
    "        df = pd.read_csv(f'{cwd}/data/pcadata_TMLung.csv')\n",
    "        X_train = df.values[:,0:(df.shape[1]-1)]\n",
    "        y_train = df.values[:,df.shape[1]-1]\n",
    "    \n",
    "    elif dataset =='TMLungLA':\n",
    "        df = pd.read_csv(f'{cwd}/data/pcadata_TMLung_WithLocAvg.csv')\n",
    "        X_train = df.values[:,0:(df.shape[1]-1)]\n",
    "        y_train = df.values[:,df.shape[1]-1]\n",
    "\n",
    "    elif dataset =='TMPanc':\n",
    "        df = pd.read_csv(f'{cwd}/data/pcadata_TMPanc.csv')\n",
    "        X_train = df.values[:,0:(df.shape[1]-1)]\n",
    "        y_train = df.values[:,df.shape[1]-1]\n",
    "    \n",
    "    elif dataset =='TMPancLA':\n",
    "        df = pd.read_csv(f'{cwd}/data/pcadata_TMPanc_WithLocAvg.csv')\n",
    "        X_train = df.values[:,0:(df.shape[1]-1)]\n",
    "        y_train = df.values[:,df.shape[1]-1]\n",
    "            \n",
    "    # get and plot embeddings\n",
    "    for alpha in alpha_list:\n",
    "        a = float(alpha) # alpha as float\n",
    "\n",
    "        # scale UMAP, PCA embeddings by alpha, (1-alpha) respectively\n",
    "        umapM_sc = umapM * (a) # sc for scaled\n",
    "        pcaM_sc = pcaM * (1-a)\n",
    "        # concatenate\n",
    "        concat_emb = np.concatenate((pcaM_sc,umapM_sc), axis=1)\n",
    "        # reduce\n",
    "        y = reducer.fit_transform(concat_emb)\n",
    "        y = y / LA.norm(y) # normalize scale to 1   \n",
    "\n",
    "        result = dict()\n",
    "        result['dataset'] = dataset\n",
    "        result['alpha'] = alpha\n",
    "\n",
    "\n",
    "        rt_acc = np.zeros(5,)\n",
    "        for i in range(5):\n",
    "            rt_acc[i] = random_triplet_eval(X_train, embedding, y_train) #X_train, embedding, labels\n",
    "        rt = np.mean(rt_acc)\n",
    "        result['rt'] = rt\n",
    "\n",
    "        knn = knn_eval(embedding, y_train, n_neighbors = 5)\n",
    "        result['knn'] = knn\n",
    "\n",
    "        result['rt-knn'] = (rt + knn)#/2 possibly\n",
    "\n",
    "        ogf = (rt + knn - mu)/sigma\n",
    "        result['ogf'] = ogf\n",
    "\n",
    "        results.append(result)\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drpaper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
